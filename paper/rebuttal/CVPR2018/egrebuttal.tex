\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{makecell}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,linkcolor=blue,citecolor=blue,bookmarks=false]{hyperref}

%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{0125} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Rebuttal for `Guided Proofreading of Automatic Segmentations for Connectomics'}  % **** Enter the paper title here

\maketitle
\thispagestyle{empty}

Thank you for your time and feedback.

\paragraph{R2: Venue} R2 writes ``While solid work, the paper is not a perfect fit for CVPR''. Biological and Cell Microscopy Image Analysis is included in the call for papers of CVPR 2018, and the field of connectomics has previously given rise to interesting papers at CVPR (Kumar~\etal 2010, Kaynig~\etal 2010, Jain~\etal 2010, Funke~\etal 2012, Pape~\etal 2017). %We believe our method will also be interesting to researchers working on tasks beyond connectomics, as segmentation proofreading for labeled dataset collection and correction is widely applicable in computer vision.

\paragraph{R2: Algorithmic Contribution/Innovation}

\paragraph{R2: Superhuman Accuracy on the SNEMI3D Challenge} \cite{superhuman_performance}

\paragraph{R2: Variation of Information Metric} \cite{NunezIglesias2013Machine}

\begin{figure}[h]
\begin{center}
  \includegraphics[width=\linewidth]{gfx/are_plot.pdf}
\end{center}
\vspace{-4mm}
   \caption{Adapted Rand Error distributions of novices and experts using guided proofreading (GP) and focused proofreading (FP) as part of the forced choice user experiment across slices of the AC4 subvolume.}
\label{fig:randerror}
\end{figure}

\paragraph{R2: Generalization of the AC4 Subvolume} R2 questions the generalization ability of the AC4 subvolume due to small dimensions. We agree that this dataset is small. However, it was introduced by Haehn~\etal 2014 for feasible interactive proofreading studies and is representative for the full AC4 dataset with respect to the distribution of object sizes.

\paragraph{R3: U-Net training data} R3 requests further information regarding the training data of the U-Net membrane probability classifier. Section 2 of the supplemental material includes this information (supplemental material lines 140-161, Table 3). We will modify the manuscript (lines 492-493) to include a direct reference.

\paragraph{R3: Generalization to other segmentation problems} R3 misses a  discussion regarding applicability of GP to general semantic segmentation problems. We believe our method will also be interesting to researchers working on tasks beyond connectomics, as segmentation proofreading for labeled dataset collection and correction is widely applicable in computer vision. We state mandatory re-training of GP for other datasets as a limitation in the supplemental material (lines 134-138) but will further elaborate on general segmentation problems in this section.

\paragraph{R3+R4: Network input channels} R3 is interested in seeing the performance contribution of the different input channels. R4 suggests that the membrane probabilities and the dilated border mask provide more discriminative information than the other two channels. We observe that all four input channels are important to reduce VI (Table~\ref{tab:input_channels}). Similar as identified by Bogovich~\etal, image data adds intracellular structures (e.g. vesicles) to the decision process and membrane probabilities include global knowledge of the staining protocol to highlight cell membranes. We then notice, that the label channel provides knowledge about neuron shapes while the border mask covers the gap of extra-cellular space.

\begin{table}[h]
\caption{We evaluate automatic selection on the AC4 subvolume ($p_t=0.95$) using the GP classifier with different input channels and report median VI reduction. The combination of all four channels performs best.}
\resizebox{\linewidth}{!}{
\begin{tabular}{lrrrr}
\toprule
\makecell{Input channels} & \makecell{VI reduction} \\
\midrule
\emph{Image + Prob.} &  -0.094\\
\emph{Image + Prob. + Border} & -0.045\\
\emph{Image + Prob. + Label} & 0.038\\
\emph{Image + Prob. + Label + Border} & 0.065\\
\bottomrule
\end{tabular} 
}
\label{tab:input_channels}
\end{table}

\paragraph{R4: Dilated mask of the border between two segments} R4 raises the question of whether the dilated mask of the border is a crucial input to our classifier. 


The dilated border improves classifier performance measured as VI reduction from $0.038$ to $0.065$ (Table~\ref{tab:input_channels}). We qualitatively describe the intention behind the border mask in lines 315-323 but will add the experiment above to the supplemental material and to the open source repository.

\paragraph{R4: 2D Slices only}

\paragraph{R4: Merge error detection performance} R4 expresses concerns regarding the performance contribution of merge error correction. 





{\small
\bibliographystyle{ieee}
\bibliography{../../connectomics}
}

\end{document}
